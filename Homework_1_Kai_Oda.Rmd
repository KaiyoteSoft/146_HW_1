---
title: "Homework 1"
author: "Kai Oda"
date: "1/9/2020"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set("~/Biology/146/Homework 1 Files")
library(ggplot2)
library(ggridges)
library(gridExtra)
library(dplyr)
library(tidyverse)
library(ggpmisc)

```

## Introduction

In this homework, you will learn how to:

* Perform basic data manipulations
    * Import data
    * Make data frames
    * Subset data
    * Edit cells in data frames
    * Search for patterns in strings
    * Join data tables

* Extract summary statistics
    * Mean, median, sd, var
    * See how statistics change based on sample size

* Create several different plots using ggplot
    * Histograms and density plots
    * Column plot
    * Boxplot, violin plot, density ridges that compare 2+ variables
    * Scatterplots and smoothers
    
    
General instructions: Complete all parts of each question, making sure that you answer in writing when relevant. In several places, clues for functions have been provided and you should fill in code where you see "...". Remember to use the help tab in R studio to look up functions. You can find lots of help online, including on our Piazza site.

### Q.1: Caffeine in Coffee (25 pts)

#### a. Import the caffeine dataset and save it as a dataframe titled "caffeine". (1pt)

```{r}
#I had to open the caffeine.xls file and resave as a .csv. 
## File type should be adjusted for newer students (originally came as a .xlsx NOT a csv)
caffeine <- read.csv("caffeine.csv")
#Changes column names to nicer names
names(caffeine) = c("Brand", "Caffeine")

```

#### b. What are the dimensions of the dataframe? (1pt)

```{r}
#Using the dimensions function 
dim(caffeine)
#14 rows, 2 columns
```
## Dimensions 
14 rows 
2 columns 

#### c. What are the data types in this data frame? (2pts)

```{r}
#typeof(caffeine)
#Supplies information on the data type of each column 
sapply(caffeine, class)
##Supplies information on the data type of each column plus some extra information 
str(caffeine)

```
1. Factor (Categorical, nominal)
2. Numeric (Continuous)

#### d. Compute the mean, standard deviation, and variance for the amount of caffeine for each type of bean. (3pts)
__What are the different types of beans? So far it only looks like there is one type of bean: "Big Bean"__
```{r}
mean(caffeine$Caffeine)
sd(caffeine$Caffeine)
var(caffeine$Caffeine)

```

Mean = 188.06
Standard Deviation = 35.575
Variation = 1265.61


#### e. Create a histogram showing the distribution of caffeine using base plots (3pts)

```{r}
hist(caffeine$Caffeine, main="Distribution of caffeine", 
     xlab="Caffeine (mg in 16 oz)")
```

#### f. Using ggplot, create a histogram and pick an appropriate binwidth (3pts)

```{r}
# change name for ease (do not change this line)
names(caffeine)[2] <- "caffeine_total"

#creating the histrogram with ggplot 
ggplot(caffeine, aes(x=caffeine_total))+
         geom_histogram(binwidth = 10, 
                        color="black", 
                        fill="white")+
  labs(x="Caffeine total (mg in a 16oz cup)", y="Frequency")

```


We are now interested in seeing how the size of subsamples of this dataset affect our estimates of the mean and standard deviation.

#### g. Using the sample() function, create 10 samples of size 3 and calculate their means (6pts)

```{r}
# Step by step:

# First create a sample of size 3 to test the function
sample(10,3)
#?sample

# Repeat this 10 times using the replicate function and save as samp3
samp3 <- replicate(10, sample(caffeine$caffeine_total,3), simplify = "array")
#?replicate

# Calculate the mean and sd for each column using the apply function
mean3 <- apply(samp3, 2, mean)
sd3 <- apply(samp3, 2, sd)
#?apply

# Create histograms for the mean and standard deviation values
#creating the histrogram with ggplot 
# ggplot(mean3, aes(x=mean3))+
#          geom_histogram(binwidth = 10, 
#                         color="black", 
#                         fill="white")+
#   labs(x="Mean", y="Frequency")

hist(mean3, main="Histogram for means", 
     xlab="Mean")
hist(sd3, main="Histogram for standard deviation", 
     xlab="Standard Deviation")

```


#### Now take what you've done in part g and repeat for samples of sizes 4-14
(Note: this part doesn't require to you do anything except run the chunk, but you should read the code to see what's happening)

```{r}

# There are lots of different ways to do this, but we are going to use a loop here because it is a bit more intuitive.

# Start by making an empty dataframe that will be filled in by the loop:
caffeine_samples <- data.frame(size=NULL, mean=NULL, sd=NULL)

# Loop for each sample size from 4 to 14
for(i in 4:14){ 

# A loop starts with a specification of the range of the loop. When you hit enter, R will start with the first number (4) and plug it in everywhere that there is an "i". When it gets to the bottom, it will return to the top and plug in the next number, repeating until it reaches the last number (14).
  
  sample_temp <- replicate(10,sample(caffeine$caffeine_total, i))
  mean_temp <- apply(sample_temp, 2, mean)
  sd_temp <- apply(sample_temp, 2, sd)
  
  # now put those results in the dataframe
  caffeine_samples <- rbind(caffeine_samples, data.frame(size=rep(i,10), mean=mean_temp, sd=sd_temp))
  
}

head(caffeine_samples)
hist(caffeine_samples$mean, main="Histogram for mean values",
     xlab="Mean")

```

#### i. Now generate a meaningful plot (or two plots) of the caffeine_samples dataframe that shows the relationship between sample size, mean, and standard deviation (4pts)

```{r}

plot1 <- ggplot(caffeine_samples, aes(x=size, y=mean))+
  geom_point()+
  labs(x="Sample size", y="Mean (mg)")+
  geom_smooth(method="lm")+
  ggtitle("Distribution of means vs sample size")

plot2 <- ggplot(caffeine_samples, aes(x=size, y=sd))+
  geom_point()+
  geom_smooth(method="lm")+
  labs(x="Sample size", y="Standard Deviation (mg)")+
  ggtitle("Distribution of SD vs sample size")

# Easy way to put multiple plots together
gridExtra::grid.arrange(plot1, plot2, ncol=2)

```

#### j. In a sentence or two, explain what your graphs show. (2pts)

As you increase the sample size the means becomes more precise. 
Similarily, increasing the sample size results in a SD closer to the actual value. However, increasing the sample size does not change the value of the mean or standard deviation.

### Q2. Desert Bird Census (20pts)

Import the desert birds dataset as "birds". 

```{r}
birds <- read.csv("desert_birds.csv")

head(birds)
str(birds)
summary(birds)

str(caffeine)
summary(caffeine)

```

#### a. Create a histogram showing the distribution of the count of birds (1pt)

```{r}
ggplot(birds, aes(x=Count))+
  geom_histogram(binwidth=20)+
  labs(x="Bird count", y="Frequency")+
  theme_bw()

## caffeine histogram 
ggplot(caffeine, aes(x=caffeine_total))+
         geom_histogram(binwidth = 10, 
                        color="black", 
                        fill="white")+
  labs(x="Caffeine total (mg)", y="Frequency")

```

#### b. Compare and contrast this distribution with the one from the caffeine dataset. Include information about the median and the mean. (3pts)

The median of the "birds" dataset is 18, compared to a median of 176.2 in the caffeine datset. The mean of the birds dataset is 74.77 compared to a mean of 188.1 in the caffeine dataset. 
The birds dataset is relatively more right skewed compared to the caffeine dataset. However, there are a few bird counts that are much larger than the rest of the data, leading to a mean that is larger than the median. Conversely, the median and mean for the caffeine dataset is relatively similar as the data is more evenly distributed. 

#### c. Using the which.max and which.min functions, return the two bird species with the highest count and the lowest count. (2pts)
Hint: you can use indices to do this in one line for each species. What does bird[1,] return? What does the which.max function return? How can you combine these?

```{r}
# count(birds)
# birds[1:43, ]
# 
# x <- c(1:5, 0:15, 11)
# View(x)
# ## Which.max returns the row number of the highest value 
# which.max(x)

#So the highest value in the "count" column is in row 8 
#which.max(birds$Count)
#And then you can find which species that value corresponds to by referencing the row number in the 
## birds datset 
birds[which.max(birds$Count), ]

#which.min(birds$Count)
birds[which.min(birds$Count), ]
```


#### d. You decide that you're only interested in looking at birds that represent 90% of the total counts. Create a subset of the data that only contains those more common birds. (6pts)
It's not uncommon in ecology to restrict our analyses to species that comprise the majority of counts because there can be computational errors when there are many species with few observations.

```{r}
# First calculate the fraction that each species represents of the whole and save in a new column named "fraction".
count_total <- sum(birds$Count)

birds$fraction <- birds$Count/count_total


# Now order the dataframe in descending order based on this fraction.
birds <- birds[order(birds$fraction, decreasing=TRUE),]
length(birds$Species)

# Use the cumsum function to calculate the cumulative sum of the fractions and save in another column.
birds$cumsum <- cumsum(birds$fraction)
#cumsum(1:4)

# Now subset your data to include only the birds with the cumulative sum <90%.
## second argument is the logic to exclude certain values 
## third argument is which columns to keep from the original dataset 
bird_sub <- subset(birds, birds$cumsum<0.9)

## You can also do this with indices:
birds_sub <- birds[which(birds$cumsum <0.9),]

# birds_sub_2 <- birds[which(birds$cumsum <0.9), ]
View(bird_sub)
length(birds_sub$Species)


# how many bird species are there in the dataset?
43

# how many species accounted for 90% of the counts?
14

```

[Fill in below:]
There are __43__ species in the dataset, but only __14__ accounted for 90% of the counts.


#### d. Extract subsets of the data by matching text strings

You can also use R to deal with text, including searching through strings.
Let's say we want to extract counts from only certain types of birds.

```{r}
# Ex. extract information about vultures using the grep() function
#?grep
grep("Vulture",birds$Species)
# This tells me that rows 14 and 20 contain vultures

# I can make a mini dataframe by simply using the indices:
birds[c(23,30),]

# I can do this in one line like so:
birds[grep("Vulture",birds$Species),]

```
#### Your turn: make two mini dataframes of 1) cowbirds and 2) doves (4pts)

```{r}
cowbirds <- birds[grep("Cowbird",birds$Species), ]
head(cowbirds)

doves <- birds[grep("Dove", birds$Species), ]
head(doves)
```

#### e. Combining data frames

You realize that you're a bit limited in your dataset and you'd like to add more information that you gathered about these birds for inclusion in later analyses. You found this great paper online (https://esajournals.onlinelibrary.wiley.com/doi/epdf/10.1890/13-1917.1) that provides metadata on bird and mammal species. However, you *really* do not want to have to open up Excel and manually type in all the additional data. Luckily, R has a couple of handy functions to help you combine these datasets. Let's walk through that process.

#### Using the new data created below, combine with the birds dataset and make a plot. (4pts)
Hint: it is easiest to change the name of the column containing the common names in either one of the two dataframes so that they match in order to combine them. Consider using the merge() function or left_join() function in the dplyr package.

```{r}

new_birds <- read.delim("BirdFuncDat.txt") # read.delim is used for .txt files
dim(new_birds)
names(new_birds)
#changes the name of column 9 from "English" to "Species"
names(new_birds)[9] <- "Species"

# combine tables
birds2 <- merge(birds,new_birds,by="Species")

# There are likely some NA values which mean that some species had no match. You can see which ones using a line of code like this:
birds2$Species[which(is.na(birds2$SpecID))]

# It looks like many of these are missing because the names are abbreviated. One option is to manually change the names in your small dataset to the full names to see if you get more matches (rather than manually searching through the new_birds dataset). Another is to use the View() function and manually search using ctrl+F. Sometimes you might need to do a little research to see if there are synonyms (e.g. there is a Rock Dove in our dataset, but a Rock Pigeon in the new dataset). You'll learn how to edit values within R in the next question. For now we will proceed with a quick plot.

# Make a plot of your choosing using the new data.
ggplot(birds2, aes(x=Species,y=Diet.Inv))+
  geom_col()+
  labs(x="Species", y="Invertebrates consumed")+
  theme_bw()+
  theme(axis.text.x = element_text(angle=90, hjust=1, vjust=0.6))

# We will come back to larger datasets like these later in the quarter. You might find this to be useful resource for your final projects.

```


### Q3. Endangered Species (20pts)

Import the endangered dataset and save as a dataframe named "endangered".


```{r}

endangered <- read.csv("endangered.csv")

```


#### a. You realize that there is a mistake in the dataframe -- there are actually 93 endangered mammals. Change this value in the dataframe using indices. (3pts)

```{r}
dim(endangered)
endangered[1, 3] <- 93

```

#### a. Using ggplot, construct a column graph that displays the taxon on the x axis and the number of species on the y axis. Color-code the columns by vertebrate status. (5pts)

```{r}
str(endangered)
# if (endangered$vertebrate=="yes") {
#   print("Hello world")
# }

ggplot(endangered, aes(x=taxon, y=no.species))+
  geom_col(aes(fill=vertebrate))+
  labs(x="Taxon", y="Number of endangered species")

```

#### b. Clean up your graph by sorting the counts in descending order using the reorder function, renaming the axes, and giving the plot a title. (5pts)
Hint: you will want to use the reorder function with the first argument being the taxon, and the second being the number of species. You can make it descending by using a minus sign.

```{r}
#?reorder
ggplot(endangered , aes(x=reorder(taxon, -no.species), y=no.species))+
  geom_col(aes(fill=vertebrate))+
  labs(x="Taxon", y ="Number of species")+
  ggtitle("Number of endangered species by taxon")+
  theme(plot.title = element_text(hjust=0.5))

```

In general, you will want to take the time to make sure your graphics look neat and readable like this in your assignments going forward.

#### c. You now want to compare the distribution of vertebrates and non-vertebrates using several plots. Create 3 plots -- a boxplot, violin plot, and density ridge plot using ggplot (6pts)

```{r}

box1 <- ggplot(endangered, aes(x=vertebrate, y=no.species))+
  geom_boxplot()

#  
violin1 <- ggplot(endangered, aes(x=vertebrate, y=no.species))+
  geom_violin()

#  
ridge1 <- ggplot(endangered, aes(x=no.species, y=vertebrate))+
  geom_density_ridges(aes(color=vertebrate,fill=vertebrate),alpha=0.3)

grid.arrange(box1,violin1,ridge1, ncol=2)

```


### Q4: Mammal brain and body size (35pts)

Import the mammals dataset and check out the first couple of rows.

```{r}

mammals <- read.csv("mammals.csv")
head(mammals)

```
#### a. Change the column names to something easy to work with and sensible (2pts)
```{r}
names(mammals) = c("name", "body_mass", "brain_mass")
head(mammals)
str(mammals)
```


#### b. Create a plot that you think will be interesting and informative. Write a sentence about what you notice about the data. (5pts)

```{r}
ggplot(mammals, aes(x=body_mass, y=brain_mass))+
  geom_point()+
  labs(x="Body mass",y="Brain mass")+
  geom_smooth(method="lm")+
  stat_fit_glance(method = 'lm', geom = 'text', aes(label = paste0('p = ', round(..p.value.., 3))))


```

A basic figure shows that brain mass appears to linearly increase with body mass — the apparently linear trend is an interesting observation. 

#### b. What variable could you create that would help you to standardize brain mass among all these different mammals? (3pts)

The brain mass of the animals should be **divided** by the body mass to get a ratio of brain-to-body mass. 

#### c. Create that variable in a new column and name it appropriately. Display the summary statistics for the new dataframe using summary(). (5pts)

```{r}

mammals$brain_ratio <- mammals$brain_mass/mammals$body_mass
summary(mammals)
View(mammals)

```

#### d. Now create a new graph that shows the relationship between this variable and the logarithm of body mass. Using geom_hline() draw a straight line showing the mean ratio and label the points with the species names using geom_text(). (10pts)

```{r}

ggplot(mammals, aes(x=log10(body_mass), y=brain_ratio))+
  geom_point()+
  geom_hline(yintercept=mean(mammals$brain_ratio))+
  geom_text(aes(label=name), size=3, vjust="inward", hjust="inward", check_overlap = T)+
  labs(x="Body mass (log)", y="Brain-to-body ratio ")


```

#### e. Write 2-3 sentences explaining your observations. What does it mean to be above the line or below the line? What do you notice about the types of mammal on either side of the line in general? (8pts)
If the species is above the horizontal line than the animal has a higher than average brain-to-body mass ratio. However, if the species is below the horizontal line than the animal has a lower than average brain-to-body mass ratio. High ratio animals include primates such as monkeys as well as humans (arguably the most intelligent species in the dataset). However, there are some low ratio animals that are recognized as intelligent, like the Asian and African elephant. 


#### f. Do you think this is a good measure of animal intelligence? Why? (2pts)
Hint: check out https://en.wikipedia.org/wiki/Brain-to-body_mass_ratio

The basic ratio is not a good measure of animal intelligence, but it can be made better by adjusting certain parameters. For example, the article notes that as the animal gets larger the brain-to-body ratio decreases. Therefore, large animals like humans, elephants and whales can have relatively low brain-to-body ratios despite being very intelligent. However, among animals of similar weights and morphologies, brain-to-body ratios can be used as a quick test to examine intelligence as a higher density of neurons could lead to more complex behaviors. 

